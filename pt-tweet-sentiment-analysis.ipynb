{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filename):\n",
    "    texts = []\n",
    "    sentiments = []\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        spamreader = csv.reader(csvfile, delimiter=';')\n",
    "        next(spamreader)\n",
    "        for row in spamreader:\n",
    "            texts.append(row[1])\n",
    "            sentiments.append(int(row[3]))\n",
    "    return texts, sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, train_sentiment = load_dataset('archive/TrainingDatasets/Train100.csv')\n",
    "test_text, test_sentiment = load_dataset('archive/TestDatasets/Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 142144\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "train_text = [nltk.word_tokenize(text) for text in train_text]\n",
    "vocab = set()\n",
    "for text in train_text:\n",
    "    vocab.update(text.lower())\n",
    "\n",
    "vocab = list(vocab)\n",
    "print('Vocab size:', len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok2idx = {tok:i+2 for i,tok in enumerate(vocab)}\n",
    "tok2idx['<pad>'] = 0\n",
    "tok2idx['<oov>'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_len = max(len(text) for text in train_text)\n",
    "max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_sentence(text):\n",
    "    vec = np.zeros(max_seq_len)\n",
    "    for i in range(len(text)):\n",
    "        if i >= max_seq_len:\n",
    "            return vec\n",
    "        token = text[i].lower()\n",
    "        if token in tok2idx:\n",
    "            vec[i] = tok2idx[token]\n",
    "        else:\n",
    "            vec[i] = 1\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 63697.,  70046.,  87568., 138097.,  51753.,  75163.,  61443.,\n",
       "       141203.,  74094.,      0.,      0.,      0.,      0.,      0.,\n",
       "            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "            0.,      0.,      0.])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_sentence(train_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([vec_sentence(text) for text in train_text])\n",
    "Y_train = np.array(train_sentiment)\n",
    "X_test = np.array([vec_sentence(text) for text in test_text])\n",
    "Y_test = np.array(test_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 63697.,  70046.,  87568., ...,      0.,      0.,      0.],\n",
       "       [ 34349., 108569., 109118., ...,      0.,      0.,      0.],\n",
       "       [100467.,  81089.,  31976., ...,      0.,      0.,      0.],\n",
       "       ...,\n",
       "       [ 99707.,  60282., 121234., ...,      0.,      0.,      0.],\n",
       "       [ 34349., 102434.,  76099., ...,      0.,      0.,      0.],\n",
       "       [ 83308.,  57722., 138097., ...,      0.,      0.,      0.]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test, Y_test))\n",
    "\n",
    "train_ds = train_ds.shuffle(len(train_ds)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.batch(len(test_ds)).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(len(tok2idx), 32),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64, return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64, return_sequences=False)),\n",
    "    tf.keras.layers.Dense(64),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, None, 32)          4548672   \n",
      "_________________________________________________________________\n",
      "bidirectional_14 (Bidirectio (None, None, 128)         37632     \n",
      "_________________________________________________________________\n",
      "bidirectional_15 (Bidirectio (None, 128)               74496     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 4,669,121\n",
      "Trainable params: 4,669,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=['accuracy'], optimizer='Adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 1668s 1s/step - loss: 0.0312 - accuracy: 0.9906\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 949s 607ms/step - loss: 0.0090 - accuracy: 0.9977\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 877s 561ms/step - loss: 0.0031 - accuracy: 0.9990\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 888s 568ms/step - loss: 0.0013 - accuracy: 0.9996\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 900s 576ms/step - loss: 8.9467e-04 - accuracy: 0.9997\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 14s 14s/step - loss: 0.1715 - accuracy: 0.9676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.17150534689426422, 0.9675999879837036]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_pred > 0.5)\n",
    "\n",
    "plt.matshow(cm)\n",
    "plt.xlabel('true')\n",
    "plt.ylabel('pred')\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(i, j, cm[i,j], ha='center', va='center')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
